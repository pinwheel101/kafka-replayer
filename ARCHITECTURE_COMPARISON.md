# 아키텍처 비교: 중간 저장 vs 직접 전송

## 기존 방식 (2-Phase 아키텍처)

```
┌─────────────────────────────────────────────────────────────┐
│ Phase 1: Spark (데이터 준비)                                 │
│  Hive Table ──▶ Spark SQL ──▶ Parquet 청크 ──▶ HDFS        │
│                  (정렬)         (1시간 단위)                 │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼ (HDFS I/O)
┌─────────────────────────────────────────────────────────────┐
│ Phase 2: Kotlin (정밀 리플레이)                              │
│  HDFS ──▶ Parquet Reader ──▶ HashedWheelTimer ──▶ Kafka    │
│            (청크 로드)         (±1-5ms 정밀도)              │
└─────────────────────────────────────────────────────────────┘
```

### 장점
✅ **밀리초 단위 정밀도**: ±1-5ms 타이밍 정확도
✅ **재사용 가능**: 같은 데이터 여러 번 리플레이
✅ **장애 복구**: 체크포인트에서 재개 가능
✅ **검증 가능**: 중간 데이터 확인 후 실행

### 단점
❌ **중복 저장**: Hive → HDFS 재저장 (스토리지 2배)
❌ **추가 I/O**: Write → Read 두 번
❌ **처리 시간**: Parquet 쓰기 시간 추가
❌ **복잡도**: 두 개 시스템 운영 (Spark + Kotlin)
❌ **비용**: HDFS 스토리지 비용

### 적합한 경우
- **밀리초 단위 정밀 타이밍** 필수
- 같은 데이터를 **반복 리플레이**
- **A/B 테스트**: 동일 데이터로 여러 시나리오

---

## 새로운 방식 (Direct Replay)

```
┌─────────────────────────────────────────────────────────────┐
│ Spark Only (All-in-One)                                      │
│  Hive Table ──▶ Spark SQL ──▶ Batch Control ──▶ Kafka      │
│                  (정렬)        (초 단위 간격)                │
└─────────────────────────────────────────────────────────────┘
```

### 장점
✅ **단순함**: 단일 Spark 작업으로 완료
✅ **빠름**: I/O 50% 감소 (중간 저장 없음)
✅ **비용 절감**: HDFS 스토리지 불필요
✅ **운영 간소화**: Kotlin 애플리케이션 불필요

### 단점
❌ **낮은 정밀도**: 초 단위 간격 (±수백ms~수초)
❌ **재사용 불가**: 한 번 실행 후 재실행 시 Spark부터
❌ **복구 복잡**: 실패 시 처음부터 재실행

### 적합한 경우
- **대략적 시간 간격**만 필요 (몇 초 차이 OK)
- **일회성 리플레이** (재사용 불필요)
- **다른 날짜 데이터**로 반복 테스트
- **빠른 처리**가 우선

---

## 성능 비교

### 30억 건 처리 시간 (예상)

| 단계 | 기존 방식 | 새 방식 |
|------|----------|---------|
| Spark 읽기/정렬 | 1시간 | 1시간 |
| Parquet 쓰기 (HDFS) | **30분** | - |
| Parquet 읽기 | **20분** | - |
| Kafka 전송 (1x) | 24시간 | 24시간 |
| **합계 (1x 속도)** | **25.8시간** | **25시간** |
| **합계 (10x 속도)** | **3.3시간** | **3시간** |
| **합계 (최대 속도)** | **2.3시간** | **1.5시간** |

### 스토리지 비용

| 항목 | 기존 방식 | 새 방식 |
|------|----------|---------|
| Hive 원본 (ORC) | 300GB | 300GB |
| Parquet 청크 (HDFS) | **300GB** | - |
| **합계** | **600GB** | **300GB** |

**비용 절감: 50%**

---

## 타이밍 정밀도 비교

### 기존 방식 (Kotlin + HashedWheelTimer)
```
이벤트 A: 10:00:00.000
이벤트 B: 10:00:05.123  (원본 간격: 5.123초)
         ↓
리플레이: 10:00:05.125  (오차: +2ms) ✅
```

### 새 방식 (Spark Batch Control)
```
이벤트 A: 10:00:00.000
이벤트 B: 10:00:05.123  (원본 간격: 5.123초)
         ↓
리플레이: 10:00:05.400  (오차: +277ms) ⚠️
```

**정밀도 차이: ±1-5ms vs ±100-500ms**

---

## 사용 예시

### 기존 방식
```bash
# Phase 1: Spark 데이터 준비
spark-submit prepare_chunks.py \
  --source-table mydb.events \
  --target-date 2021-01-02 \
  --output-path hdfs:///replay/prepared/2021-01-02

# Phase 2: Kotlin 리플레이
java -jar kafka-replayer.jar \
  --mode time-synced \
  --input-path /replay/prepared/2021-01-02 \
  --speed 2.0
```

### 새 방식
```bash
# All-in-One: Spark만 사용
spark-submit replay_direct_to_kafka.py \
  --source-table mydb.events \
  --target-date 2021-01-02 \
  --kafka-bootstrap kafka:9092 \
  --topic events-replay \
  --speed 2.0
```

---

## 선택 가이드

### 기존 방식 (2-Phase) 선택 시
- [ ] 밀리초 단위 정밀 타이밍 필수
- [ ] 같은 데이터를 여러 번 리플레이
- [ ] 중간 검증 필요
- [ ] 스토리지 비용 문제 없음

### 새 방식 (Direct) 선택 시 ✅
- [x] 몇 초 오차 허용
- [x] 일회성 리플레이
- [x] 빠른 처리 우선
- [x] 비용 절감 중요
- [x] 운영 단순화

---

## 하이브리드 접근

두 방식을 병행 사용:

1. **개발/테스트**: Direct 방식 (빠른 반복)
2. **프로덕션**: 기존 방식 (정밀 재현)

또는:

1. **일반 리플레이**: Direct 방식
2. **정밀 시뮬레이션**: 기존 방식 (특수 케이스만)

---

## 결론

**요구사항에 따라:**
- 시간 간격이 "**대략 비슷**"하면 충분 → **Direct 방식** 권장 🌟
- "**정확히 1.5ms 후**" 필요 → 기존 방식 유지

**대부분의 경우 Direct 방식으로 충분합니다!**
